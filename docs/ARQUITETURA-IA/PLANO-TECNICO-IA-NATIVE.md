# üöÄ PLANO T√âCNICO - TRANSFORMA√á√ÉO IA-NATIVE

**Data:** Janeiro 2025  
**Arquiteta:** IA S√™nior - PostgreSQL, pgvector, Prisma, RAG  
**Objetivo:** Transformar CMS em plataforma IA-native sem quebrar compatibilidade

---

## üìã SUM√ÅRIO EXECUTIVO

Este documento define o plano t√©cnico completo para transformar o CMS Moderno em uma plataforma IA-native usando **PostgreSQL + pgvector + RAG**, mantendo 100% de compatibilidade com o c√≥digo existente.

**Princ√≠pios:**
- ‚úÖ Apenas adi√ß√µes (zero remo√ß√µes)
- ‚úÖ Backward compatible 100%
- ‚úÖ Multi-tenancy preservado
- ‚úÖ Enterprise-grade

---

## 1Ô∏è‚É£ INSTALA√á√ÉO DO PGVECTOR

### **1.1. SQL de Instala√ß√£o**

```sql
-- Habilitar extens√£o pgvector no PostgreSQL
CREATE EXTENSION IF NOT EXISTS vector;

-- Verificar instala√ß√£o
SELECT * FROM pg_extension WHERE extname = 'vector';
```

**Quando executar:**
- **Desenvolvimento:** Na primeira migra√ß√£o
- **Produ√ß√£o:** Via migration Prisma ou manualmente (com permiss√µes adequadas)

### **1.2. Escolha de √çndice: HNSW vs IVFFLAT**

#### **HNSW (Hierarchical Navigable Small World)**
```sql
-- Recomendado para produ√ß√£o
CREATE INDEX ON embeddings USING hnsw (embedding vector_cosine_ops);
```

**Quando usar HNSW:**
- ‚úÖ **Produ√ß√£o** (melhor performance)
- ‚úÖ **Busca r√°pida** (< 10ms)
- ‚úÖ **Alta concorr√™ncia**
- ‚úÖ **Dados que n√£o mudam frequentemente**
- ‚ö†Ô∏è **Maior uso de mem√≥ria** (~30% mais que IVFFLAT)
- ‚ö†Ô∏è **Build mais lento** (mas aceit√°vel para embeddings)

#### **IVFFLAT (Inverted File with Flat Compression)**
```sql
-- Alternativa para desenvolvimento/testes
CREATE INDEX ON embeddings USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);
```

**Quando usar IVFFLAT:**
- ‚úÖ **Desenvolvimento** (build mais r√°pido)
- ‚úÖ **Dados que mudam frequentemente**
- ‚úÖ **Menor uso de mem√≥ria**
- ‚ö†Ô∏è **Performance inferior** (~50-100ms vs <10ms)
- ‚ö†Ô∏è **Requer rebuild** quando dados mudam muito

**DECIS√ÉO T√âCNICA:** Usar **HNSW** em produ√ß√£o, IVFFLAT apenas para desenvolvimento/testes.

---

## 2Ô∏è‚É£ MODELAGEM DO BANCO (PRISMA)

### **2.1. Nova Tabela: `Embedding`**

```prisma
model Embedding {
  id            String   @id @default(cuid())
  
  // Relacionamento com conte√∫do
  pageId        String?
  page          Page?    @relation(fields: [pageId], references: [id], onDelete: Cascade)
  
  aiContentId   String?
  aiContent     AIContent? @relation(fields: [aiContentId], references: [id], onDelete: Cascade)
  
  templateId    String?
  template      Template? @relation(fields: [templateId], references: [id], onDelete: Cascade)
  
  // Multi-tenancy (obrigat√≥rio)
  siteId        String
  site          Site     @relation(fields: [siteId], references: [id], onDelete: Cascade)
  
  organizationId String  // Denormalizado para performance
  organization   Organization @relation(fields: [organizationId], references: [id], onDelete: Cascade)
  
  // Dados do embedding
  embedding     Unsupported("vector(1536)")  // pgvector - OpenAI ada-002 padr√£o
  model         String   @default("text-embedding-ada-002") // Modelo usado
  dimensions    Int      @default(1536) // Dimens√µes do vetor
  
  // Metadados
  contentType   String   // "page", "ai_content", "template"
  contentHash   String   // Hash do conte√∫do original (evitar duplicatas)
  language      String   @default("pt-BR")
  
  // Versionamento
  version       Int      @default(1) // Vers√£o do embedding (se conte√∫do mudar)
  isActive      Boolean  @default(true) // Embedding ativo ou obsoleto
  
  // Timestamps
  createdAt     DateTime @default(now())
  updatedAt     DateTime @updatedAt
  
  // √çndices
  @@index([siteId, contentType, isActive], name: "embedding_site_content_idx")
  @@index([organizationId, contentType], name: "embedding_org_content_idx")
  @@index([contentHash], name: "embedding_hash_idx")
  @@index([model, dimensions], name: "embedding_model_idx")
  @@map("embeddings")
}
```

**Justificativas T√©cnicas:**
1. **`Unsupported("vector(1536)")`**: Prisma n√£o suporta nativamente pgvector. Usamos `Unsupported` e gerenciamos via SQL raw.
2. **`organizationId` denormalizado**: Evita JOINs desnecess√°rios em buscas sem√¢nticas (performance cr√≠tica).
3. **`contentHash`**: Evita gerar embeddings duplicados (economia de custos).
4. **`version` + `isActive`**: Permite versionamento e reindexa√ß√£o sem perder hist√≥rico.
5. **M√∫ltiplos relacionamentos opcionais**: Um embedding pode ser de Page, AIContent ou Template.

---

### **2.2. Nova Tabela: `AIInteraction`**

```prisma
model AIInteraction {
  id            String   @id @default(cuid())
  
  // Multi-tenancy
  organizationId String
  organization   Organization @relation(fields: [organizationId], references: [id], onDelete: Cascade)
  
  siteId        String?
  site          Site?    @relation(fields: [siteId], references: [id], onDelete: SetNull)
  
  userId        String?
  user          User?    @relation(fields: [userId], references: [id], onDelete: SetNull)
  
  // Relacionamento com conte√∫do (opcional)
  aiContentId   String?
  aiContent     AIContent? @relation(fields: [aiContentId], references: [id], onDelete: SetNull)
  
  pageId        String?
  page          Page?    @relation(fields: [pageId], references: [id], onDelete: SetNull)
  
  // Tipo de intera√ß√£o
  type          String   // "rag_query", "content_generation", "regeneration", "diagnostic", "suggestion"
  status        String   @default("pending") // "pending", "processing", "completed", "failed"
  
  // Prompt e contexto
  prompt        String   // Prompt original do usu√°rio
  promptVersion String?  // Vers√£o do prompt usado (refer√™ncia a AIPrompt)
  context       String?  @default("{}") // JSON - contexto usado (RAG, etc)
  
  // Modelo usado
  provider      String   // "openai", "gemini", "claude"
  model         String   // "gpt-4o-mini", "gemini-2.0-flash", etc
  temperature   Float?   @default(0.7)
  maxTokens     Int?
  
  // Resposta
  response      String?  // Resposta da IA
  finishReason  String?  // "stop", "length", "content_filter", etc
  
  // M√©tricas de tokens
  promptTokens      Int?
  completionTokens  Int?
  totalTokens       Int?
  
  // M√©tricas de custo
  costUSD           Float?  // Custo em USD
  costBRL           Float?  // Custo em BRL (se aplic√°vel)
  
  // M√©tricas de performance
  durationMs        Int?    // Tempo total em milissegundos
  embeddingDurationMs Int?  // Tempo para gerar/buscar embeddings
  aiCallDurationMs  Int?    // Tempo da chamada √† IA
  
  // RAG espec√≠fico
  ragUsed           Boolean @default(false)
  ragChunksCount    Int?    // Quantidade de chunks usados no contexto
  ragSimilarityThreshold Float? @default(0.7) // Threshold de similaridade usado
  
  // Erros
  errorMessage      String?
  errorCode         String?
  retryCount        Int     @default(0)
  
  // Timestamps
  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt
  completedAt       DateTime?
  
  // √çndices
  @@index([organizationId, type, status], name: "ai_interaction_org_type_status_idx")
  @@index([siteId, createdAt], name: "ai_interaction_site_created_idx")
  @@index([userId, createdAt], name: "ai_interaction_user_created_idx")
  @@index([provider, model], name: "ai_interaction_provider_model_idx")
  @@index([createdAt], name: "ai_interaction_created_at_idx")
  @@map("ai_interactions")
}
```

**Justificativas T√©cnicas:**
1. **Rastreamento completo**: Cada intera√ß√£o com IA √© registrada (auditoria completa).
2. **M√©tricas detalhadas**: Tokens, custo, tempo (permite dashboards futuros).
3. **RAG tracking**: Campos espec√≠ficos para rastrear uso de RAG.
4. **Multi-tenancy**: Filtros por organizationId e siteId garantem isolamento.

---

### **2.3. Nova Tabela: `AIMetric`**

```prisma
model AIMetric {
  id            String   @id @default(cuid())
  
  // Multi-tenancy
  organizationId String?
  organization   Organization? @relation(fields: [organizationId], references: [id], onDelete: Cascade)
  
  siteId        String?
  site          Site?    @relation(fields: [siteId], references: [id], onDelete: Cascade)
  
  userId        String?
  user          User?    @relation(fields: [userId], references: [id], onDelete: SetNull)
  
  // Agrega√ß√£o temporal
  period        String   // "hour", "day", "week", "month"
  periodStart   DateTime // In√≠cio do per√≠odo
  periodEnd     DateTime // Fim do per√≠odo
  
  // Agrega√ß√£o por tipo
  type          String?  // "rag_query", "content_generation", etc (null = todos)
  provider      String?  // "openai", "gemini", etc (null = todos)
  model         String?  // Modelo espec√≠fico (null = todos)
  
  // M√©tricas agregadas
  totalRequests     Int     @default(0)
  successfulRequests Int    @default(0)
  failedRequests    Int     @default(0)
  
  totalTokens       BigInt  @default(0)
  promptTokens      BigInt  @default(0)
  completionTokens  BigInt  @default(0)
  
  totalCostUSD      Decimal @default(0) @db.Decimal(10, 4)
  totalCostBRL      Decimal @default(0) @db.Decimal(10, 4)
  
  avgDurationMs     Int?    // Dura√ß√£o m√©dia em ms
  p50DurationMs     Int?    // Percentil 50
  p95DurationMs     Int?    // Percentil 95
  p99DurationMs     Int?    // Percentil 99
  
  // RAG espec√≠fico
  ragRequestsCount  Int     @default(0)
  avgRagChunksCount Float?  // M√©dia de chunks por RAG
  
  // Timestamps
  createdAt     DateTime @default(now())
  updatedAt     DateTime @updatedAt
  
  // √çndices
  @@unique([organizationId, siteId, userId, period, periodStart, type, provider, model], name: "ai_metric_unique_idx")
  @@index([organizationId, period, periodStart], name: "ai_metric_org_period_idx")
  @@index([siteId, period, periodStart], name: "ai_metric_site_period_idx")
  @@index([periodStart, periodEnd], name: "ai_metric_period_range_idx")
  @@map("ai_metrics")
}
```

**Justificativas T√©cnicas:**
1. **Agrega√ß√£o pr√©-calculada**: Evita queries pesadas em dashboards (performance).
2. **M√∫ltiplos n√≠veis de granularidade**: Por organiza√ß√£o, site, usu√°rio.
3. **Percentis**: P50, P95, P99 para an√°lise de performance.
4. **Unique constraint**: Evita duplicatas e permite upsert eficiente.

---

### **2.4. Nova Tabela: `AIPrompt`**

```prisma
model AIPrompt {
  id            String   @id @default(cuid())
  
  // Multi-tenancy
  organizationId String?
  organization   Organization? @relation(fields: [organizationId], references: [id], onDelete: Cascade)
  
  siteId        String?
  site          Site?    @relation(fields: [siteId], references: [id], onDelete: Cascade)
  
  // Identifica√ß√£o
  name          String   // Nome do prompt (ex: "content_generation_blog_post")
  slug          String   // Slug √∫nico
  description   String?  // Descri√ß√£o do prompt
  
  // Versionamento
  version       Int      @default(1)
  isActive      Boolean  @default(true)
  isDefault     Boolean  @default(false) // Vers√£o padr√£o
  
  // Conte√∫do
  prompt        String   // Template do prompt
  variables     String   @default("[]") // JSON array - vari√°veis dispon√≠veis
  
  // Configura√ß√µes
  provider      String?  // "openai", "gemini", etc (null = qualquer)
  model         String?  // Modelo recomendado (null = qualquer)
  temperature   Float?   @default(0.7)
  maxTokens     Int?
  
  // Categoria
  category      String   // "content_generation", "rag_query", "diagnostic", "editing", etc
  
  // Metadados
  tags          String?  // Tags separadas por v√≠rgula
  examples      String?  @default("[]") // JSON array - exemplos de uso
  
  // Auditoria
  createdBy     String?  // userId que criou
  updatedBy     String?  // userId que atualizou
  
  // Timestamps
  createdAt     DateTime @default(now())
  updatedAt     DateTime @updatedAt
  
  // √çndices
  @@unique([slug, version], name: "ai_prompt_slug_version_idx")
  @@index([organizationId, siteId, category, isActive], name: "ai_prompt_org_site_category_idx")
  @@index([category, isDefault], name: "ai_prompt_category_default_idx")
  @@map("ai_prompts")
}
```

**Justificativas T√©cnicas:**
1. **Versionamento**: Permite evoluir prompts sem quebrar funcionalidades existentes.
2. **Multi-tenancy**: Prompts podem ser customizados por organiza√ß√£o/site.
3. **Vari√°veis**: Template system permite reutiliza√ß√£o.
4. **Auditoria**: Rastreia quem criou/atualizou.

---

## 3Ô∏è‚É£ ALTERA√á√ïES ADITIVAS EM MODELS EXISTENTES

### **3.1. Model `Page` - Adi√ß√µes**

```prisma
model Page {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS CAMPOS (aditivos apenas)
  embeddingGeneratedAt DateTime? // Quando o embedding foi gerado
  embeddingModel       String?   // Modelo usado para gerar embedding
  embeddingVersion     Int       @default(1) // Vers√£o do embedding
  
  // NOVOS RELACIONAMENTOS
  embeddings Embedding[]
  aiInteractions AIInteraction[]
  
  // ... resto do model permanece igual ...
}
```

---

### **3.2. Model `AIContent` - Adi√ß√µes**

```prisma
model AIContent {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS CAMPOS (aditivos apenas)
  embeddingGeneratedAt DateTime?
  embeddingModel       String?
  embeddingVersion     Int       @default(1)
  
  // NOVOS RELACIONAMENTOS
  embeddings Embedding[]
  aiInteractions AIInteraction[]
  
  // ... resto do model permanece igual ...
}
```

---

### **3.3. Model `Template` - Adi√ß√µes**

```prisma
model Template {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS CAMPOS (aditivos apenas)
  embeddingGeneratedAt DateTime?
  embeddingModel       String?
  embeddingVersion     Int       @default(1)
  
  // NOVOS RELACIONAMENTOS
  embeddings Embedding[]
  
  // ... resto do model permanece igual ...
}
```

---

### **3.4. Model `AIContentHistory` - Adi√ß√µes**

```prisma
model AIContentHistory {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS CAMPOS (aditivos apenas)
  tokensUsed      Int?    // Tokens usados nesta a√ß√£o
  costUSD         Float?  // Custo em USD
  durationMs      Int?    // Dura√ß√£o em ms
  modelUsed       String? // Modelo usado
  providerUsed    String? // Provider usado
  
  // NOVO RELACIONAMENTO
  aiInteractionId String?
  aiInteraction   AIInteraction? @relation(fields: [aiInteractionId], references: [id], onDelete: SetNull)
  
  // ... resto do model permanece igual ...
}
```

---

### **3.5. Model `Organization` - Adi√ß√µes**

```prisma
model Organization {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS RELACIONAMENTOS
  embeddings Embedding[]
  aiInteractions AIInteraction[]
  aiMetrics AIMetric[]
  aiPrompts AIPrompt[]
  
  // ... resto do model permanece igual ...
}
```

---

### **3.6. Model `Site` - Adi√ß√µes**

```prisma
model Site {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS RELACIONAMENTOS
  embeddings Embedding[]
  aiInteractions AIInteraction[]
  aiMetrics AIMetric[]
  aiPrompts AIPrompt[]
  
  // ... resto do model permanece igual ...
}
```

---

### **3.7. Model `User` - Adi√ß√µes**

```prisma
model User {
  // ... campos existentes (N√ÉO ALTERAR) ...
  
  // NOVOS RELACIONAMENTOS
  aiInteractions AIInteraction[]
  aiMetrics AIMetric[]
  aiPromptsCreated AIPrompt[] @relation("AIPromptCreatedBy")
  aiPromptsUpdated AIPrompt[] @relation("AIPromptUpdatedBy")
  
  // ... resto do model permanece igual ...
}
```

---

## 4Ô∏è‚É£ √çNDICES E PERFORMANCE

### **4.1. √çndice Vetorial (pgvector)**

```sql
-- √çndice HNSW para busca sem√¢ntica (produ√ß√£o)
CREATE INDEX embeddings_embedding_hnsw_idx 
ON embeddings 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Par√¢metros HNSW:
-- m = 16: N√∫mero de conex√µes bidirecionais (padr√£o recomendado)
-- ef_construction = 64: Tamanho da lista din√¢mica durante constru√ß√£o
```

**Quando usar:**
- ‚úÖ Busca sem√¢ntica (RAG)
- ‚úÖ Similaridade de conte√∫do
- ‚úÖ Recomenda√ß√µes

---

### **4.2. √çndices Compostos para Multi-tenancy**

```sql
-- √çndice para busca por site + tipo + status
CREATE INDEX embeddings_site_content_active_idx 
ON embeddings (site_id, content_type, is_active)
WHERE is_active = true;

-- √çndice para m√©tricas por organiza√ß√£o + per√≠odo
CREATE INDEX ai_metrics_org_period_idx 
ON ai_metrics (organization_id, period, period_start DESC);

-- √çndice para intera√ß√µes recentes por site
CREATE INDEX ai_interactions_site_recent_idx 
ON ai_interactions (site_id, created_at DESC)
WHERE status = 'completed';
```

**Justificativas:**
- **Filtros multi-tenancy primeiro**: Garante isolamento antes de busca vetorial.
- **WHERE clauses**: √çndices parciais para dados ativos apenas (menor tamanho).
- **DESC**: Para queries de "√∫ltimos N" mais r√°pidas.

---

## 5Ô∏è‚É£ PIPELINE DE EMBEDDINGS

### **5.1. Fluxo de Gera√ß√£o de Embeddings**

```
1. EVENTO DISPARADOR
   ‚îú‚îÄ Cria√ß√£o de Page/AIContent/Template
   ‚îú‚îÄ Edi√ß√£o de conte√∫do existente
   ‚îî‚îÄ Reindexa√ß√£o manual (admin)

2. VALIDA√á√ÉO
   ‚îú‚îÄ Verificar se conte√∫do mudou (contentHash)
   ‚îú‚îÄ Verificar se embedding j√° existe e est√° atualizado
   ‚îî‚îÄ Se n√£o mudou ‚Üí SKIP

3. GERA√á√ÉO ASS√çNCRONA (QueueJob)
   ‚îú‚îÄ Criar QueueJob tipo "generate_embedding"
   ‚îú‚îÄ Status: "pending"
   ‚îî‚îÄ Retornar resposta imediata ao usu√°rio

4. PROCESSAMENTO (Worker)
   ‚îú‚îÄ Buscar QueueJob
   ‚îú‚îÄ Gerar embedding via OpenAI/Gemini
   ‚îú‚îÄ Calcular contentHash
   ‚îú‚îÄ Verificar duplicatas
   ‚îú‚îÄ Salvar Embedding no banco
   ‚îú‚îÄ Atualizar Page/AIContent/Template (embeddingGeneratedAt)
   ‚îî‚îÄ Marcar QueueJob como "completed"

5. TRATAMENTO DE ERROS
   ‚îú‚îÄ Se falhar ‚Üí retry (at√© 3x)
   ‚îú‚îÄ Se ainda falhar ‚Üí marcar como "failed"
   ‚îî‚îÄ Log de erro para debug
```

---

### **5.2. C√≥digo: Gera√ß√£o de Embedding**

```typescript
// lib/embedding-service.ts

import { db } from '@/lib/db'
import { QueueJob } from '@prisma/client'
import { AIService } from '@/lib/ai-services'
import crypto from 'crypto'

interface GenerateEmbeddingParams {
  contentType: 'page' | 'ai_content' | 'template'
  contentId: string
  content: string
  siteId: string
  organizationId: string
  language?: string
}

export class EmbeddingService {
  private static readonly EMBEDDING_MODEL = 'text-embedding-ada-002'
  private static readonly EMBEDDING_DIMENSIONS = 1536
  
  /**
   * Gera hash do conte√∫do para evitar duplicatas
   */
  private static generateContentHash(content: string): string {
    return crypto.createHash('sha256').update(content).digest('hex')
  }
  
  /**
   * Verifica se embedding j√° existe e est√° atualizado
   */
  private static async checkExistingEmbedding(
    contentType: string,
    contentId: string,
    contentHash: string
  ): Promise<boolean> {
    const existing = await db.$queryRaw`
      SELECT id FROM embeddings
      WHERE 
        ${contentType}_id = ${contentId}
        AND content_hash = ${contentHash}
        AND is_active = true
      LIMIT 1
    `
    
    return existing.length > 0
  }
  
  /**
   * Gera embedding via OpenAI
   */
  private static async generateEmbeddingVector(
    content: string
  ): Promise<number[]> {
    const aiService = new AIService({
      id: 'embedding-service',
      name: 'Embedding Service',
      type: 'openai',
      status: 'active',
      credentials: {
        apiKey: process.env.OPENAI_API_KEY!,
        endpoint: 'https://api.openai.com/v1'
      },
      settings: {},
      lastUsed: new Date(),
      usage: { requests: 0, tokens: 0, cost: 0 },
      createdAt: new Date(),
      updatedAt: new Date()
    })
    
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: this.EMBEDDING_MODEL,
        input: content
      })
    })
    
    if (!response.ok) {
      throw new Error(`OpenAI embedding error: ${response.statusText}`)
    }
    
    const data = await response.json()
    return data.data[0].embedding
  }
  
  /**
   * Salva embedding no banco (via SQL raw devido ao pgvector)
   */
  private static async saveEmbedding(
    params: GenerateEmbeddingParams,
    embedding: number[],
    contentHash: string
  ): Promise<string> {
    const embeddingId = crypto.randomUUID()
    
    // Usar SQL raw para inserir vector
    await db.$executeRaw`
      INSERT INTO embeddings (
        id,
        ${params.contentType}_id,
        site_id,
        organization_id,
        embedding,
        model,
        dimensions,
        content_type,
        content_hash,
        language,
        version,
        is_active,
        created_at,
        updated_at
      ) VALUES (
        ${embeddingId}::uuid,
        ${params.contentId}::uuid,
        ${params.siteId}::uuid,
        ${params.organizationId}::uuid,
        ${JSON.stringify(embedding)}::vector,
        ${this.EMBEDDING_MODEL},
        ${this.EMBEDDING_DIMENSIONS},
        ${params.contentType},
        ${contentHash},
        ${params.language || 'pt-BR'},
        1,
        true,
        NOW(),
        NOW()
      )
    `
    
    return embeddingId
  }
  
  /**
   * M√©todo principal: Gera embedding (ass√≠ncrono via QueueJob)
   */
  static async generateEmbedding(
    params: GenerateEmbeddingParams
  ): Promise<{ queued: boolean; jobId?: string }> {
    // 1. Validar conte√∫do
    if (!params.content || params.content.trim().length === 0) {
      throw new Error('Content is required')
    }
    
    // 2. Gerar hash
    const contentHash = this.generateContentHash(params.content)
    
    // 3. Verificar se j√° existe
    const exists = await this.checkExistingEmbedding(
      params.contentType,
      params.contentId,
      contentHash
    )
    
    if (exists) {
      return { queued: false }
    }
    
    // 4. Criar QueueJob
    const job = await db.queueJob.create({
      data: {
        type: 'generate_embedding',
        status: 'pending',
        data: JSON.stringify(params),
        maxAttempts: 3
      }
    })
    
    // 5. Processar em background (ou via worker)
    this.processEmbeddingJob(job.id).catch(console.error)
    
    return { queued: true, jobId: job.id }
  }
  
  /**
   * Processa job de embedding (worker)
   */
  private static async processEmbeddingJob(jobId: string): Promise<void> {
    const job = await db.queueJob.findUnique({ where: { id: jobId } })
    
    if (!job || job.status !== 'pending') {
      return
    }
    
    try {
      // Atualizar status
      await db.queueJob.update({
        where: { id: jobId },
        data: { status: 'processing' }
      })
      
      // Parse params
      const params = JSON.parse(job.data) as GenerateEmbeddingParams
      
      // Gerar embedding
      const embedding = await this.generateEmbeddingVector(params.content)
      const contentHash = this.generateContentHash(params.content)
      
      // Salvar
      const embeddingId = await this.saveEmbedding(params, embedding, contentHash)
      
      // Atualizar conte√∫do original
      const updateData: any = {
        embeddingGeneratedAt: new Date(),
        embeddingModel: this.EMBEDDING_MODEL,
        embeddingVersion: 1
      }
      
      if (params.contentType === 'page') {
        await db.page.update({
          where: { id: params.contentId },
          data: updateData
        })
      } else if (params.contentType === 'ai_content') {
        await db.aIContent.update({
          where: { id: params.contentId },
          data: updateData
        })
      } else if (params.contentType === 'template') {
        await db.template.update({
          where: { id: params.contentId },
          data: updateData
        })
      }
      
      // Marcar job como completo
      await db.queueJob.update({
        where: { id: jobId },
        data: {
          status: 'completed',
          result: JSON.stringify({ embeddingId }),
          processedAt: new Date()
        }
      })
      
    } catch (error) {
      // Marcar como falha
      await db.queueJob.update({
        where: { id: jobId },
        data: {
          status: 'failed',
          error: error instanceof Error ? error.message : 'Unknown error',
          attempts: { increment: 1 }
        }
      })
      
      // Retry se ainda tiver tentativas
      const updatedJob = await db.queueJob.findUnique({ where: { id: jobId } })
      if (updatedJob && updatedJob.attempts < updatedJob.maxAttempts) {
        // Reagendar (exemplo: ap√≥s 5 minutos)
        setTimeout(() => {
          this.processEmbeddingJob(jobId).catch(console.error)
        }, 5 * 60 * 1000)
      }
    }
  }
}
```

---

### **5.3. Reindexa√ß√£o**

```typescript
// lib/embedding-reindex-service.ts

export class EmbeddingReindexService {
  /**
   * Reindexa todos os conte√∫dos de um site
   */
  static async reindexSite(siteId: string): Promise<{ queued: number }> {
    // Buscar todas as p√°ginas
    const pages = await db.page.findMany({
      where: { siteId },
      select: { id: true, content: true }
    })
    
    // Buscar todos os conte√∫dos IA
    const aiContents = await db.aIContent.findMany({
      where: { siteId },
      select: { id: true, content: true }
    })
    
    // Buscar todos os templates
    const templates = await db.template.findMany({
      select: { id: true, content: true }
    })
    
    let queued = 0
    
    // Gerar embeddings para p√°ginas
    for (const page of pages) {
      if (page.content) {
        await EmbeddingService.generateEmbedding({
          contentType: 'page',
          contentId: page.id,
          content: page.content,
          siteId,
          organizationId: (await db.site.findUnique({ where: { id: siteId } }))!.organizationId
        })
        queued++
      }
    }
    
    // Gerar embeddings para conte√∫dos IA
    for (const content of aiContents) {
      if (content.content) {
        await EmbeddingService.generateEmbedding({
          contentType: 'ai_content',
          contentId: content.id,
          content: content.content,
          siteId,
          organizationId: (await db.site.findUnique({ where: { id: siteId } }))!.organizationId
        })
        queued++
      }
    }
    
    // Gerar embeddings para templates
    for (const template of templates) {
      if (template.content) {
        const site = await db.site.findFirst({ where: { id: siteId } })
        if (site) {
          await EmbeddingService.generateEmbedding({
            contentType: 'template',
            contentId: template.id,
            content: template.content,
            siteId,
            organizationId: site.organizationId
          })
          queued++
        }
      }
    }
    
    return { queued }
  }
}
```

---

## 6Ô∏è‚É£ FLUXO RAG (PASSO A PASSO)

### **6.1. Diagrama de Fluxo**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usu√°rio   ‚îÇ
‚îÇ   Pergunta  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Identificar      ‚îÇ
‚îÇ    Contexto          ‚îÇ
‚îÇ  - siteId           ‚îÇ
‚îÇ  - organizationId   ‚îÇ
‚îÇ  - language         ‚îÇ
‚îÇ  - contentType      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Gerar Embedding  ‚îÇ
‚îÇ    da Pergunta      ‚îÇ
‚îÇ  (OpenAI ada-002)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Busca Sem√¢ntica  ‚îÇ
‚îÇ    (pgvector)       ‚îÇ
‚îÇ  - Similarity > 0.7 ‚îÇ
‚îÇ  - Filtro siteId    ‚îÇ
‚îÇ  - Limite: 5 chunks ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Montar Contexto  ‚îÇ
‚îÇ  - Ordenar por      ‚îÇ
‚îÇ    similaridade     ‚îÇ
‚îÇ  - Adicionar        ‚îÇ
‚îÇ    metadados        ‚îÇ
‚îÇ  - Limitar tokens   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Chamar IA        ‚îÇ
‚îÇ  - OpenAI/Gemini    ‚îÇ
‚îÇ  - Prompt + Contexto ‚îÇ
‚îÇ  - Rastrear tokens   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Persistir        ‚îÇ
‚îÇ  - AIInteraction    ‚îÇ
‚îÇ  - M√©tricas         ‚îÇ
‚îÇ  - Resposta         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Resposta   ‚îÇ
‚îÇ  ao Usu√°rio ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### **6.2. C√≥digo: Servi√ßo RAG**

```typescript
// lib/rag-service.ts

import { db } from '@/lib/db'
import { EmbeddingService } from './embedding-service'
import { AIService } from './ai-services'

interface RAGQueryParams {
  query: string
  siteId: string
  organizationId: string
  userId?: string
  language?: string
  contentType?: 'page' | 'ai_content' | 'template' | 'all'
  maxChunks?: number
  similarityThreshold?: number
  provider?: 'openai' | 'gemini'
  model?: string
}

interface RAGResponse {
  answer: string
  chunks: Array<{
    id: string
    contentType: string
    contentId: string
    content: string
    similarity: number
  }>
  metrics: {
    tokensUsed: number
    costUSD: number
    durationMs: number
  }
}

export class RAGService {
  /**
   * Executa query RAG completa
   */
  static async query(params: RAGQueryParams): Promise<RAGResponse> {
    const startTime = Date.now()
    
    // 1. Gerar embedding da pergunta
    const queryEmbedding = await EmbeddingService.generateEmbeddingVector(params.query)
    
    // 2. Busca sem√¢ntica no pgvector
    const chunks = await this.semanticSearch({
      queryEmbedding,
      siteId: params.siteId,
      organizationId: params.organizationId,
      contentType: params.contentType || 'all',
      maxChunks: params.maxChunks || 5,
      similarityThreshold: params.similarityThreshold || 0.7
    })
    
    // 3. Montar contexto
    const context = this.buildContext(chunks)
    
    // 4. Chamar IA
    const aiResponse = await this.callAI({
      query: params.query,
      context,
      provider: params.provider || 'openai',
      model: params.model
    })
    
    // 5. Persistir intera√ß√£o
    const interaction = await db.aiInteraction.create({
      data: {
        organizationId: params.organizationId,
        siteId: params.siteId,
        userId: params.userId,
        type: 'rag_query',
        status: 'completed',
        prompt: params.query,
        provider: aiResponse.provider,
        model: aiResponse.model,
        response: aiResponse.answer,
        promptTokens: aiResponse.usage.promptTokens,
        completionTokens: aiResponse.usage.completionTokens,
        totalTokens: aiResponse.usage.totalTokens,
        costUSD: aiResponse.usage.costUSD,
        durationMs: Date.now() - startTime,
        ragUsed: true,
        ragChunksCount: chunks.length,
        ragSimilarityThreshold: params.similarityThreshold || 0.7,
        completedAt: new Date()
      }
    })
    
    return {
      answer: aiResponse.answer,
      chunks: chunks.map(c => ({
        id: c.id,
        contentType: c.contentType,
        contentId: c.contentId,
        content: c.content,
        similarity: c.similarity
      })),
      metrics: {
        tokensUsed: aiResponse.usage.totalTokens,
        costUSD: aiResponse.usage.costUSD,
        durationMs: Date.now() - startTime
      }
    }
  }
  
  /**
   * Busca sem√¢ntica usando pgvector
   */
  private static async semanticSearch(params: {
    queryEmbedding: number[]
    siteId: string
    organizationId: string
    contentType: string
    maxChunks: number
    similarityThreshold: number
  }): Promise<Array<{
    id: string
    contentType: string
    contentId: string
    content: string
    similarity: number
  }>> {
    // SQL raw para busca vetorial
    const contentTypeFilter = params.contentType === 'all' 
      ? '' 
      : `AND content_type = '${params.contentType}'`
    
    const results = await db.$queryRaw<Array<{
      id: string
      content_type: string
      page_id: string | null
      ai_content_id: string | null
      template_id: string | null
      similarity: number
    }>>`
      SELECT 
        e.id,
        e.content_type,
        e.page_id,
        e.ai_content_id,
        e.template_id,
        1 - (e.embedding <=> ${JSON.stringify(params.queryEmbedding)}::vector) as similarity
      FROM embeddings e
      WHERE 
        e.site_id = ${params.siteId}::uuid
        AND e.organization_id = ${params.organizationId}::uuid
        AND e.is_active = true
        ${contentTypeFilter}
      ORDER BY e.embedding <=> ${JSON.stringify(params.queryEmbedding)}::vector
      LIMIT ${params.maxChunks}
    `
    
    // Filtrar por threshold e buscar conte√∫do
    const chunks = []
    for (const result of results) {
      if (result.similarity >= params.similarityThreshold) {
        // Buscar conte√∫do original
        let content = ''
        let contentId = ''
        
        if (result.page_id) {
          const page = await db.page.findUnique({
            where: { id: result.page_id },
            select: { content: true }
          })
          content = page?.content || ''
          contentId = result.page_id
        } else if (result.ai_content_id) {
          const aiContent = await db.aIContent.findUnique({
            where: { id: result.ai_content_id },
            select: { content: true }
          })
          content = aiContent?.content || ''
          contentId = result.ai_content_id
        } else if (result.template_id) {
          const template = await db.template.findUnique({
            where: { id: result.template_id },
            select: { content: true }
          })
          content = template?.content || ''
          contentId = result.template_id
        }
        
        if (content) {
          chunks.push({
            id: result.id,
            contentType: result.content_type,
            contentId,
            content,
            similarity: result.similarity
          })
        }
      }
    }
    
    return chunks
  }
  
  /**
   * Monta contexto para a IA
   */
  private static buildContext(chunks: Array<{ content: string; similarity: number }>): string {
    const contextParts = chunks
      .sort((a, b) => b.similarity - a.similarity)
      .map((chunk, index) => `[${index + 1}] ${chunk.content}`)
      .join('\n\n')
    
    return `Contexto relevante encontrado:\n\n${contextParts}`
  }
  
  /**
   * Chama IA com contexto
   */
  private static async callAI(params: {
    query: string
    context: string
    provider: 'openai' | 'gemini'
    model?: string
  }): Promise<{
    answer: string
    provider: string
    model: string
    usage: {
      promptTokens: number
      completionTokens: number
      totalTokens: number
      costUSD: number
    }
  }> {
    const prompt = `Com base no contexto fornecido abaixo, responda √† pergunta do usu√°rio de forma precisa e √∫til.

${params.context}

Pergunta do usu√°rio: ${params.query}

Resposta:`
    
    const aiService = new AIService({
      id: 'rag-service',
      name: 'RAG Service',
      type: params.provider,
      status: 'active',
      credentials: {
        apiKey: params.provider === 'openai' 
          ? process.env.OPENAI_API_KEY!
          : process.env.GOOGLE_API_KEY!,
        endpoint: params.provider === 'openai'
          ? 'https://api.openai.com/v1'
          : 'https://generativelanguage.googleapis.com/v1beta'
      },
      settings: {},
      lastUsed: new Date(),
      usage: { requests: 0, tokens: 0, cost: 0 },
      createdAt: new Date(),
      updatedAt: new Date()
    })
    
    const response = await aiService.generateContent({
      prompt,
      model: params.model || (params.provider === 'openai' ? 'gpt-4o-mini' : 'gemini-2.0-flash'),
      maxTokens: 2000,
      temperature: 0.7,
      type: 'text'
    })
    
    if (!response.success || !response.data) {
      throw new Error(response.error || 'AI generation failed')
    }
    
    return {
      answer: response.data.content,
      provider: params.provider,
      model: response.data.model,
      usage: {
        promptTokens: response.usage?.promptTokens || 0,
        completionTokens: response.usage?.completionTokens || 0,
        totalTokens: response.usage?.totalTokens || 0,
        costUSD: response.usage?.cost || 0
      }
    }
  }
}
```

---

## 7Ô∏è‚É£ ORQUESTRA√á√ÉO DE IA EVOLU√çDA

### **7.1. Evolu√ß√£o do AIOrchestrator**

```typescript
// lib/ai-orchestrator-v2.ts

import { db } from '@/lib/db'
import { AIService } from './ai-services'

interface AIOrchestratorRequest {
  type: 'rag_query' | 'content_generation' | 'editing_review' | 'multimodal' | 'wordpress_diagnostic'
  prompt: string
  context?: any
  siteId: string
  organizationId: string
  userId?: string
  priority?: 'low' | 'medium' | 'high'
  multimodal?: boolean
  maxTokens?: number
  temperature?: number
  preferredProvider?: 'openai' | 'gemini'
}

interface AIOrchestratorResponse {
  model: string
  provider: string
  content: string
  interactionId: string
  usage: {
    tokens: number
    costUSD: number
    durationMs: number
  }
  metadata: {
    fallbackUsed: boolean
    decisionReason: string
  }
}

export class AIOrchestratorV2 {
  /**
   * Seleciona modelo baseado em regras + hist√≥rico
   */
  private async selectModel(request: AIOrchestratorRequest): Promise<{
    provider: 'openai' | 'gemini'
    model: string
    reason: string
  }> {
    // 1. Verificar prefer√™ncia do usu√°rio
    if (request.preferredProvider) {
      return {
        provider: request.preferredProvider,
        model: request.preferredProvider === 'openai' ? 'gpt-4o-mini' : 'gemini-2.0-flash',
        reason: 'user_preference'
      }
    }
    
    // 2. Verificar hist√≥rico de sucesso por tipo
    const recentInteractions = await db.aiInteraction.findMany({
      where: {
        organizationId: request.organizationId,
        type: request.type,
        status: 'completed',
        createdAt: {
          gte: new Date(Date.now() - 7 * 24 * 60 * 60 * 1000) // √öltimos 7 dias
        }
      },
      orderBy: { createdAt: 'desc' },
      take: 100
    })
    
    // Calcular taxa de sucesso por provider
    const openaiSuccess = recentInteractions
      .filter(i => i.provider === 'openai')
      .reduce((acc, i) => acc + (i.status === 'completed' ? 1 : 0), 0) / 
      Math.max(recentInteractions.filter(i => i.provider === 'openai').length, 1)
    
    const geminiSuccess = recentInteractions
      .filter(i => i.provider === 'gemini')
      .reduce((acc, i) => acc + (i.status === 'completed' ? 1 : 0), 0) / 
      Math.max(recentInteractions.filter(i => i.provider === 'gemini').length, 1)
    
    // 3. Regras espec√≠ficas por tipo
    if (request.type === 'multimodal' || request.multimodal) {
      return {
        provider: 'gemini',
        model: 'gemini-2.0-flash',
        reason: 'multimodal_required'
      }
    }
    
    if (request.type === 'wordpress_diagnostic' || request.priority === 'high') {
      return {
        provider: 'gemini',
        model: 'gemini-2.0-flash',
        reason: 'complex_task'
      }
    }
    
    // 4. Decis√£o baseada em custo + performance
    if (request.priority === 'low' || request.type === 'content_generation') {
      return {
        provider: 'openai',
        model: 'gpt-4o-mini',
        reason: 'cost_optimization'
      }
    }
    
    // 5. Default: melhor taxa de sucesso recente
    if (geminiSuccess > openaiSuccess + 0.1) {
      return {
        provider: 'gemini',
        model: 'gemini-2.0-flash',
        reason: 'better_success_rate'
      }
    }
    
    return {
      provider: 'openai',
      model: 'gpt-4o-mini',
      reason: 'default'
    }
  }
  
  /**
   * Processa requisi√ß√£o com fallback autom√°tico
   */
  async processRequest(request: AIOrchestratorRequest): Promise<AIOrchestratorResponse> {
    const startTime = Date.now()
    
    // Criar intera√ß√£o inicial
    const interaction = await db.aiInteraction.create({
      data: {
        organizationId: request.organizationId,
        siteId: request.siteId,
        userId: request.userId,
        type: request.type,
        status: 'processing',
        prompt: request.prompt,
        context: JSON.stringify(request.context || {}),
        createdAt: new Date()
      }
    })
    
    // Selecionar modelo
    const modelSelection = await this.selectModel(request)
    
    let response: AIOrchestratorResponse | null = null
    let fallbackUsed = false
    
    try {
      // Tentar com modelo selecionado
      response = await this.callAI({
        ...request,
        provider: modelSelection.provider,
        model: modelSelection.model,
        interactionId: interaction.id
      })
      
      // Atualizar intera√ß√£o
      await db.aiInteraction.update({
        where: { id: interaction.id },
        data: {
          status: 'completed',
          provider: modelSelection.provider,
          model: modelSelection.model,
          response: response.content,
          promptTokens: response.usage.tokens,
          totalTokens: response.usage.tokens,
          costUSD: response.usage.costUSD,
          durationMs: response.usage.durationMs,
          completedAt: new Date()
        }
      })
      
    } catch (error) {
      // Fallback: tentar com outro provider
      const fallbackProvider = modelSelection.provider === 'openai' ? 'gemini' : 'openai'
      const fallbackModel = fallbackProvider === 'openai' ? 'gpt-4o-mini' : 'gemini-2.0-flash'
      
      try {
        response = await this.callAI({
          ...request,
          provider: fallbackProvider,
          model: fallbackModel,
          interactionId: interaction.id
        })
        
        fallbackUsed = true
        
        // Atualizar intera√ß√£o com fallback
        await db.aiInteraction.update({
          where: { id: interaction.id },
          data: {
            status: 'completed',
            provider: fallbackProvider,
            model: fallbackModel,
            response: response.content,
            promptTokens: response.usage.tokens,
            totalTokens: response.usage.tokens,
            costUSD: response.usage.costUSD,
            durationMs: response.usage.durationMs,
            completedAt: new Date(),
            errorMessage: `Fallback used: ${error instanceof Error ? error.message : 'Unknown error'}`
          }
        })
        
      } catch (fallbackError) {
        // Ambos falharam
        await db.aiInteraction.update({
          where: { id: interaction.id },
          data: {
            status: 'failed',
            errorMessage: `Both providers failed. Original: ${error instanceof Error ? error.message : 'Unknown'}. Fallback: ${fallbackError instanceof Error ? fallbackError.message : 'Unknown'}`,
            errorCode: 'BOTH_PROVIDERS_FAILED'
          }
        })
        
        throw new Error('All AI providers failed')
      }
    }
    
    return {
      ...response!,
      interactionId: interaction.id,
      metadata: {
        fallbackUsed,
        decisionReason: modelSelection.reason
      }
    }
  }
  
  /**
   * Chama IA e rastreia m√©tricas
   */
  private async callAI(params: AIOrchestratorRequest & {
    provider: 'openai' | 'gemini'
    model: string
    interactionId: string
  }): Promise<AIOrchestratorResponse> {
    const startTime = Date.now()
    
    const aiService = new AIService({
      id: 'orchestrator',
      name: 'AI Orchestrator',
      type: params.provider,
      status: 'active',
      credentials: {
        apiKey: params.provider === 'openai'
          ? process.env.OPENAI_API_KEY!
          : process.env.GOOGLE_API_KEY!,
        endpoint: params.provider === 'openai'
          ? 'https://api.openai.com/v1'
          : 'https://generativelanguage.googleapis.com/v1beta'
      },
      settings: {},
      lastUsed: new Date(),
      usage: { requests: 0, tokens: 0, cost: 0 },
      createdAt: new Date(),
      updatedAt: new Date()
    })
    
    const aiResponse = await aiService.generateContent({
      prompt: params.prompt,
      model: params.model,
      maxTokens: params.maxTokens || 2000,
      temperature: params.temperature || 0.7,
      type: 'text'
    })
    
    if (!aiResponse.success || !aiResponse.data) {
      throw new Error(aiResponse.error || 'AI generation failed')
    }
    
    const durationMs = Date.now() - startTime
    
    return {
      model: params.model,
      provider: params.provider,
      content: aiResponse.data.content,
      interactionId: params.interactionId,
      usage: {
        tokens: aiResponse.usage?.totalTokens || 0,
        costUSD: aiResponse.usage?.cost || 0,
        durationMs
      },
      metadata: {
        fallbackUsed: false,
        decisionReason: ''
      }
    }
  }
}
```

---

## 8Ô∏è‚É£ SEGURAN√áA E MULTI-TENANCY

### **8.1. Garantias de Isolamento**

#### **Filtros Obrigat√≥rios em Todas as Queries**

```typescript
// Exemplo: Busca sem√¢ntica SEMPRE filtra por organizationId e siteId
const results = await db.$queryRaw`
  SELECT * FROM embeddings
  WHERE 
    organization_id = ${organizationId}::uuid  -- ‚úÖ OBRIGAT√ìRIO
    AND site_id = ${siteId}::uuid              -- ‚úÖ OBRIGAT√ìRIO
    AND is_active = true
  ORDER BY embedding <=> ${queryEmbedding}::vector
  LIMIT 10
`
```

#### **Middleware de Valida√ß√£o**

```typescript
// lib/middleware/tenant-validation.ts

export function validateTenantAccess(
  userId: string,
  organizationId: string,
  siteId?: string
): Promise<boolean> {
  // Verificar se usu√°rio pertence √† organiza√ß√£o
  // Verificar se site pertence √† organiza√ß√£o (se siteId fornecido)
  // Retornar true apenas se ambos v√°lidos
}
```

---

### **8.2. Prompts Customizados por Site**

```typescript
// Buscar prompt customizado do site, ou usar padr√£o
const prompt = await db.aiPrompt.findFirst({
  where: {
    siteId: siteId,
    category: 'content_generation',
    isActive: true,
    isDefault: true
  },
  orderBy: { version: 'desc' }
}) || await db.aiPrompt.findFirst({
  where: {
    organizationId: organizationId,
    siteId: null, // Prompt global da organiza√ß√£o
    category: 'content_generation',
    isActive: true,
    isDefault: true
  },
  orderBy: { version: 'desc' }
}) || await db.aiPrompt.findFirst({
  where: {
    organizationId: null, // Prompt global do sistema
    siteId: null,
    category: 'content_generation',
    isActive: true,
    isDefault: true
  },
  orderBy: { version: 'desc' }
})
```

**Hierarquia de Prompts:**
1. Site espec√≠fico (mais espec√≠fico)
2. Organiza√ß√£o (m√©dio)
3. Sistema (padr√£o)

---

## 9Ô∏è‚É£ CHECKLIST EXECUT√ÅVEL

### **9.1. Backend**

- [ ] **Instalar depend√™ncias**
  ```bash
  npm install @prisma/client
  # pgvector ser√° gerenciado via SQL, n√£o precisa de pacote npm
  ```

- [ ] **Criar migrations Prisma**
  ```bash
  npx prisma migrate dev --name add_ai_native_tables
  ```

- [ ] **Executar SQL de pgvector**
  ```sql
  CREATE EXTENSION IF NOT EXISTS vector;
  ```

- [ ] **Criar √≠ndices vetoriais**
  ```sql
  CREATE INDEX embeddings_embedding_hnsw_idx ON embeddings USING hnsw (embedding vector_cosine_ops);
  ```

- [ ] **Implementar EmbeddingService**
  - [ ] `lib/embedding-service.ts`
  - [ ] Gera√ß√£o de embeddings
  - [ ] Verifica√ß√£o de duplicatas
  - [ ] Integra√ß√£o com QueueJob

- [ ] **Implementar RAGService**
  - [ ] `lib/rag-service.ts`
  - [ ] Busca sem√¢ntica
  - [ ] Montagem de contexto
  - [ ] Chamada de IA

- [ ] **Evoluir AIOrchestrator**
  - [ ] `lib/ai-orchestrator-v2.ts`
  - [ ] Sele√ß√£o de modelo baseada em hist√≥rico
  - [ ] Fallback autom√°tico
  - [ ] Persist√™ncia de decis√µes

- [ ] **Criar endpoints de API**
  - [ ] `POST /api/rag/query` - Query RAG
  - [ ] `POST /api/embeddings/generate` - Gerar embedding
  - [ ] `POST /api/embeddings/reindex` - Reindexar site
  - [ ] `GET /api/ai-interactions` - Listar intera√ß√µes
  - [ ] `GET /api/ai-metrics` - M√©tricas agregadas

---

### **9.2. Banco de Dados**

- [ ] **Habilitar extens√£o pgvector**
  ```sql
  CREATE EXTENSION IF NOT EXISTS vector;
  ```

- [ ] **Executar migrations**
  ```bash
  npx prisma migrate deploy
  ```

- [ ] **Criar √≠ndices vetoriais**
  ```sql
  -- HNSW para produ√ß√£o
  CREATE INDEX embeddings_embedding_hnsw_idx 
  ON embeddings 
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
  ```

- [ ] **Criar √≠ndices compostos**
  ```sql
  CREATE INDEX embeddings_site_content_active_idx 
  ON embeddings (site_id, content_type, is_active)
  WHERE is_active = true;
  ```

- [ ] **Validar √≠ndices**
  ```sql
  SELECT * FROM pg_indexes WHERE tablename = 'embeddings';
  ```

---

### **9.3. IA**

- [ ] **Configurar chaves de API**
  - [ ] OpenAI API Key
  - [ ] Google Gemini API Key

- [ ] **Testar gera√ß√£o de embeddings**
  ```typescript
  const embedding = await EmbeddingService.generateEmbeddingVector('test content')
  console.log('Embedding dimensions:', embedding.length)
  ```

- [ ] **Testar busca sem√¢ntica**
  ```typescript
  const results = await RAGService.query({
    query: 'Como criar conte√∫do?',
    siteId: '...',
    organizationId: '...'
  })
  ```

- [ ] **Validar custos**
  - [ ] Verificar custo por embedding
  - [ ] Verificar custo por query RAG
  - [ ] Configurar alertas de limite

---

### **9.4. WordPress**

- [ ] **Reindexar conte√∫do WordPress existente**
  ```typescript
  await EmbeddingReindexService.reindexSite(siteId)
  ```

- [ ] **Configurar webhook para novos conte√∫dos**
  - [ ] Quando novo post criado ‚Üí gerar embedding
  - [ ] Quando post atualizado ‚Üí atualizar embedding

---

### **9.5. Produ√ß√£o**

- [ ] **Backup antes de deploy**
  ```bash
  pg_dump -h localhost -U user -d cms_modern > backup_before_ai_native.sql
  ```

- [ ] **Deploy em staging primeiro**
  - [ ] Testar todas as funcionalidades
  - [ ] Validar performance
  - [ ] Validar custos

- [ ] **Monitorar m√©tricas**
  - [ ] Tokens usados
  - [ ] Custos
  - [ ] Performance de busca sem√¢ntica
  - [ ] Taxa de erro

- [ ] **Configurar alertas**
  - [ ] Custo di√°rio > limite
  - [ ] Taxa de erro > threshold
  - [ ] Performance degradada

---

## üîü RESUMO T√âCNICO

### **O Que Foi Adicionado:**

1. **4 novas tabelas:**
   - `Embedding` - Armazena vetores de conte√∫do
   - `AIInteraction` - Rastreia todas as intera√ß√µes com IA
   - `AIMetric` - M√©tricas agregadas
   - `AIPrompt` - Prompts versionados

2. **Campos aditivos em tabelas existentes:**
   - `Page`, `AIContent`, `Template`: campos de embedding
   - `AIContentHistory`: m√©tricas de IA

3. **Novos servi√ßos:**
   - `EmbeddingService` - Gera√ß√£o de embeddings
   - `RAGService` - Busca sem√¢ntica e RAG
   - `AIOrchestratorV2` - Orquestra√ß√£o evolu√≠da

4. **Infraestrutura:**
   - pgvector habilitado
   - √çndices HNSW para busca r√°pida
   - √çndices compostos para multi-tenancy

### **Compatibilidade:**

- ‚úÖ **100% backward compatible**
- ‚úÖ **Nenhuma tabela removida**
- ‚úÖ **Nenhum campo alterado**
- ‚úÖ **Apenas adi√ß√µes**

### **Pr√≥ximos Passos:**

1. Executar migrations
2. Implementar servi√ßos
3. Testar em staging
4. Deploy em produ√ß√£o
5. Monitorar m√©tricas

---

**Data de Cria√ß√£o:** Janeiro 2025  
**Status:** ‚úÖ Plano T√©cnico Completo e Execut√°vel









